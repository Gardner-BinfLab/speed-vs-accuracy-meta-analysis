\documentclass[fleqn,10pt]{SelfArx} % Document font size and equations flushed left

\usepackage{float}
\usepackage{graphicx}
\usepackage{caption}
\graphicspath{{../figures/}}

\newcommand{\beginsupplement}{%
        \setcounter{table}{0}
        \renewcommand{\thetable}{S\arabic{table}}%
        \setcounter{figure}{0}
        \renewcommand{\thefigure}{S\arabic{figure}}%
     }

\definecolor{color1}{RGB}{0,0,90} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

\JournalInfo{Supplementary Text} % Journal information ``Journal, Vol. XXI, No. 1, 1-5, 2015''
\Archive{ } % Additional notes (e.g. copyright, DOI, review/research article)


\PaperTitle{Supplementary results for: A meta-analysis of bioinformatics software benchmarks reveals that publication-bias unduly influences software accuracy} % Article title

\Authors{Paul P. Gardner\textsuperscript{1,2}*, James M. Paterson\textsuperscript{3}, Stephanie McGimpsey\textsuperscript{4}, Fatemeh Ashari-Ghomi\textsuperscript{5}, Sinan U. Umu\textsuperscript{6}, Aleksandra Pawlik\textsuperscript{7},
Alex Gavryushkin\textsuperscript{8}, Michael A Black\textsuperscript{1}
} % Authors

\affiliation{\textsuperscript{1}\textit{Department of Biochemistry, University of Otago, Dunedin, New Zealand.}} % Author affiliation
\affiliation{\textsuperscript{2}\textit{Biomolecular Interaction Centre, University of Canterbury, Christchurch, New Zealand.}}
\affiliation{\textsuperscript{3}\textit{Department of Civil and Natural Resources Engineering, University of Canterbury, Christchurch, New Zealand.}}
\affiliation{\textsuperscript{4}\textit{Parasites and Microbes, Wellcome Sanger Institute, Wellcome Genome Campus, Hinxton,
8 Cambridgeshire, CB10 1RQ, UK.}}
\affiliation{\textsuperscript{5}\textit{Research Group for Genomic Epidemiology, National Food Institute, Technical University of Denmark, Kongens Lyngby, Denmark.}}
\affiliation{\textsuperscript{6}\textit{Department of Research, Cancer Registry of Norway, Oslo, Norway.}} % Author affiliation
\affiliation{\textsuperscript{7}\textit{New Zealand eScience Infrastructure, 49 Symonds St, Auckland, New Zealand.}}
\affiliation{\textsuperscript{8}\textit{Department of Computer Science, University of Otago, Dunedin, New Zealand.}} % Author affiliation

\affiliation{*\textbf{Corresponding author}: paul.gardner@otago.ac.nz} % Corresponding author

\Keywords{computational biology --- accuracy --- benchmarks --- meta-analysis --- software development} % Keywords - if you don't want any simply remove all the text between the curly brackets
\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{In the below we provide additional results for our investigation of computational biology benchmarks.}

\begin{document}

\flushbottom % Makes all text pages the same height
\maketitle % Print the title and abstract box
%\tableofcontents % Print the contents section

\thispagestyle{empty} % Removes page numbering from the first page

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\onecolumn
\beginsupplement

\section*{Literature mining} % The \section*{} command stops section numbering


\begin{figure}[H]
\centering
\includegraphics[height=0.7\textheight]{litMiningFlowDiagram-edited.pdf}
\caption{In order to improve the identification of benchmark articles
  that rank both accuracy and speed we developed a tool for ranking
  PubMed articles based upon word association scores (measured in
  ‘bits’). In brief, keywords were extracted from titles and abstracts
  for both training (in this case benchmark articles) and background
  articles (articles published between 2013 and 2015 with
  “bioinformatics” in the title or abstract). Log-odds ratios were
  computed for each keyword (measured in ‘bits’). Candidate articles
  that matched a hand-selected list of keywords associated with
  benchmarks were then scored and ranked with a “sum of bits”
  score. High ranking articles were then inspected, those that met our
  criteria were added to the training set, those that didn’t were
  added to the background set of articles.}
\label{fig:flow}
\end{figure}



\begin{figure}[H] \centering
\includegraphics[width=1.05\textwidth]{wordScores.pdf} \caption{The 40
  highest and lowest scoring words that are associated with
  bioinformatic benchmark articles from the training benchmark articles,
  compared to the background articles. The log-odds ratios (measured
  in bits) are indicated on the y-axis. }
\label{fig:wordScores} \end{figure}


%% \clearpage
%% \newpage

%% \section*{R code ...}

%% {\tiny
%% \begin{verbatim}

%% \end{verbatim}
%% }


\clearpage
\newpage

\section*{Data mining} % The \section*{} command stops section numbering

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{supplementary-figures-small.pdf}
\caption{The distributions for the measures we expected to be
  predictive of software quality used in this study. These
are, reading from left to right, top to bottom: Accuracy -- the mean
normalised accuracy rank for each benchmarked method; Speed -- the
mean normalised speed rank for each benchmarked method;
JH5 -- the Journal H5 index to the highest impact journal that has published
a manuscript describing a method, data from GoogleScholar 2020 Metrics;
Cites -- the number of citations to the most cited manuscript describing a method, data from GoogleScholar;
H-index -- the H-index for the highest profile corresponding author from the
manuscripts describing a method, data from GoogleScholar User Profiles;
M-index -- the M-index (H-index/(\#years since first publication)) for the
highest profile corresponding author from the manuscripts describing a method,
data from GoogleScholar User Profiles;
Relative ages for different tools, for each benchmark tools were ranked based upon publication dates, these ranks were normalised to lie between 0 and 1.
}
\label{fig:metricDistributions}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{supplementary-figures-pairs.pdf}
\caption{}
\label{fig:metricPairs}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{spearmanBarplot.pdf}
\includegraphics[width=0.45\textwidth]{spearmanBarplotSpeed.pdf}
\caption{The correlation between method accuracy (on the left) and
  method speed (on the right) and measures we expected to be
  predictive of software quality. E.g. author reputation measures
  (H-index, M-index), journal reputation (JH5 and JIF), number of
  users (citations and relative citations) or the recency of methods
  (year and relative age).  The correlations were estimated using
  Spearman's $\rho$. The signficant relationships are indicated with a
  ``*''. }
\label{fig:S2}
\end{figure}


%% \begin{figure}[H]
%% \centering
%% \includegraphics[width=0.5\textwidth]{smoothScatter-speed-vs-accuracy.pdf}
%% \caption{A smoothed color density representation of a scatterplot of
%%   normalised speed ranks and normalised accuracy ranks. Dark red
%%   regions are indicative of of a high density of points, blue shades
%%   indicate the reverse. The expected inverse relationship between
%%   speed and accuracy is indicated with a dashed black line, points
%%   above this line could be considered comparatively fast and accurate,
%%   points below are the reverse. A locally weighted regression (lowess)
%%   curve is shown in red.}
%% \label{fig:smoothScatterAccSpeed}
%% \end{figure}

%% \begin{figure}[H]
%% \centering
%% \includegraphics[width=0.85\textwidth]{smoothScatters.pdf}
%% \caption{A smoothed color density representation of a scatterplot of
%%   journal impact factors (JIF) on the left and number of citations on
%%   the right vs normalised accuracy ranks. As above, dark red regions
%%   are indicative of of a high density of points, blue shades indicate
%%   the reverse. The JIF for journals that are major publishers of
%%   bioinformatic software are indicated on the left. }
%% \label{fig:smoothScatters}
%% \end{figure}



\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{hindex-SpeedVsAccuracy-heatmap.pdf}
\includegraphics[width=0.45\textwidth]{cites-SpeedVsAccuracy-heatmap.pdf}
\caption{{\bf Citation metrics and software tool speeds/accuracies.} Heatmaps of normalised speed ranks and normalised accuracy
  ranks, both $x$ and $y$ dimensions are discretised into a $10 \times
  10$ matrix. The shading indicates different median citation-based
  feature scores (redder shade indicates a higher value).  The shading
  indicate median H-indices ({\bf left}) and $log_{10}(citations)$
  ({\bf right}). }
\label{fig:heatmaps}
\end{figure}


\begin{figure}[H]
\centering
%\includegraphics[width=0.95\textwidth]{relAge-SpeedVsAccuracy-heatmap-edited.pdf}
\includegraphics[width=0.45\textwidth]{relAge-speedAcc.pdf}
\includegraphics[width=0.45\textwidth]{relAge-SpeedVsAccuracy-heatmap.pdf}
\caption{{\bf Relative software tool ages and speeds/accuracies.} {\bf Left.} Violin plots for the relative age distribution
  for software tools in each of the 5 2x2 cells indicated in B. The
  five boxes correspond to the four extreme corners of the speed vs
  accuracy spectrum (i.e. slow and inaccurate, slow and accurate, fast
  and inaccurate, fast and accurate) and the central box (medium speed
  and medium accuracy). {\bf Right.} A heatmap indicating the relative age
  of software in a range of relative accuracy and speed rankings. Blue
  colours indicate an abundance of older software tools in an accuracy
  and speed category, while light colours indicate younger software in
  an accuracy and speed category. }
\label{fig:ageplot}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{commits-SpeedVsAccuracy-heatmap.pdf}
\includegraphics[width=0.45\textwidth]{contributors-SpeedVsAccuracy-heatmap.pdf}
\caption{{\bf Version control use and software tool speeds/accuracies.}
  Heatmaps of normalised speed ranks and normalised accuracy
  ranks, both $x$ and $y$ dimensions are discretised into a $10 \times
  10$ matrix. The shading indicates different median github-derived
  feature scores (redder shade indicates a higher value).  The shading
  indicate the number of commits ({\bf left}) and the number of code contributors
  ({\bf right}).
 }
\label{fig:heatmapsCommits}
\end{figure}


The complete list of benchmarks used for this study
\cite{pmid32183840,
pmid32138645,
pmid31948481,
pmid31874603,
pmid31984131,
pmid31639029,
pmid31465436,
pmid31324872,
pmid31159850,
pmid31136576,
pmid31080946,
pmid31015787,
pmid30936559,
pmid30717772,
pmid30658573,
pmid29568413,
pmid28934964,
pmid28808243,
pmid28739658,
pmid28569140,
pmid28052134,
pmid27256311,
pmid26862001,
pmid26778510,
pmid26628557,
pmid26220471,
pmid25777524,
pmid25760244,
pmid25574120,
pmid25521762,
pmid25511303,
pmid25198770,
pmid24839440,
pmid24708189,
pmid24602402,
pmid24526711,
pmid24086547,
pmid23842808,
pmid23758764,
pmid23593445,
pmid23393030,
pmid22574964,
pmid22506536,
pmid22492192,
pmid22287634,
pmid22152123,
pmid22172045,
pmid22132132,
pmid21856737,
pmid21615913,
pmid21525877,
pmid21483869,
pmid21423806,
pmid21113338,
pmid20617200,
pmid20047664,
pmid19179695,
pmid19126200,
pmid19046431,
pmid18793413,
pmid18287116,
pmid17151342,
pmid17062146,
pmid15840834,
pmid15701525,
ng2013estimating}.


%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------
\bibliographystyle{unsrt}
\bibliography{supp-references}

\end{document}








